\begin{problem}[6.2.1]
  Let
  \[%
    f_n(x) = \frac{nx}{1 + nx^2}
  .\]%
  \begin{enumerate}
    \item Find the pointwise limit of $(f_n)$ for all $x \in (0, \infty)$.

    \item is the convergence uniform on $(0, \infty)$?

    \item Is the convergence uniform on $(0, 1)$?

    \item Is the convergence uniform on $(1, \infty)$?
  \end{enumerate}
\end{problem}

\begin{proof}[Solution to (i)]
  Taking the limit as $n \to \infty$,
  \[%
    \lim_{n \to \infty} f_n(x) = \lim_{n \to \infty} \frac{nx}{1 + nx^2} = \lim_{n \to \infty} \frac{x}{\frac{1}{n} + x^2} = \frac{x}{x^2} = \frac{1}{x}
  .\qedhere\]%
\end{proof}

\begin{proof}[Solution to (ii)]
  Define $x_n = \sfrac{1}{\sqrt{n}}$. Then
  \[%
    f_n(x_n) = \frac{n \cdot \frac{1}{\sqrt{n}}}{1 + n \left(\frac{1}{n}\right)} = \frac{\sqrt{n}}{1 + 1} = \frac{\sqrt{n}}{2}
  .\]%
  Computing the difference,
  \[%
    \lvert f_n(x_n) - f(x_n) \rvert = \left\lvert \frac{\sqrt{n}}{2} - \sqrt{n} \right\rvert = \left\lvert \sqrt{n} \left( \frac{1}{2} - 1 \right) \right\rvert = \frac{\sqrt{n}}{2}
  .\]%
  Since $\sfrac{\sqrt{n}}{2} \to \infty$ as $n \to \infty$, for any fixed $\epsilon > 0$, we can always find an $x_n$ such that
  \[%
    \lvert f_n(x_n) - f(x_n) \rvert \geq 1
  .\]%
  Hence, the convergence is not uniform on $(0, \infty)$.
\end{proof}

\begin{proof}[Solution to (iii)]
  No. Suppose for contradiction that $(f_n)$ converges uniformly to $f$ on
  $(0,1)$. Then for any $\epsilon > 0$, there must exist an $N \in \mathbb{N}$
  such that for all $n \geq N$ and all $x \in (0,1)$,
  \[%
    \lvert f_n(x) - f(x) \rvert < \epsilon
  .\]%
  Define $x_n = \sfrac{1}{\sqrt{n}}$. Then,
  \[%
    f_n(x_n) = \frac{n \cdot (\sfrac{1}{\sqrt{n}})}{1 + n \left(\sfrac{1}{n}\right)} = \frac{\sqrt{n}}{1 + 1} = \frac{\sqrt{n}}{2}
  .\]%
  Computing the difference,
  \[%
    \lvert f_n(x_n) - f(x_n) \rvert = \left\lvert \frac{\sqrt{n}}{2} - \sqrt{n} \right\rvert = \left\lvert \sqrt{n} \left( \frac{1}{2} - 1 \right) \right\rvert = \frac{\sqrt{n}}{2}
  .\]%
  Since $\sfrac{\sqrt{n}}{2} \to \infty$ as $n \to \infty$, we conclude that for
  any fixed $\epsilon > 0$, there exists an $x_n$ such that
  \[%
    \lvert f_n(x_n) - f(x_n) \rvert \geq 1
  .\]%
  Hence, the convergence is not uniform on $(0,1)$.
\end{proof}

\begin{proof}[Solution to (iv)]
  Yes. Let $\epsilon > 0$. Choose $N > \sfrac{1}{\epsilon}$. Then for all $n \ge N$,
  we have
  \[%
    \lvert f_n(x) - f(x) \rvert = \frac{1}{x(1 + nx^2)} \le \frac{1}{n} \le \frac{1}{N} < \epsilon
  .\qedhere\]%
\end{proof}

\begin{problem}[6.2.3]
  For each $n \in \N$ and $x \in [0, \infty)$, let
  \[%
    g_n(x) = \frac{x}{1 + x^n} \aand h(x) = \begin{cases}
      1 & \textrm{if}~x \ge \frac{1}{n} \\
      nx & \textrm{if}~0 \le x < \frac{1}{n}
    \end{cases}
  .\]%
  Answer the following questions for the sequences $(g_n)$ and $(h_n)$:
  \begin{enumerate}
    \item Find the pointwise limit on $[0, \infty)$.

    \item Explain how we know that the convergence cannot be uniform on $[0, \infty)$.

    \item Choose a smaller set over which the convergence is uniform and supply
      an argument to show that this is indeed the case.
  \end{enumerate}
\end{problem}

\begin{proof}[Solution to (i)]
  Finding the pointwise limit,
  \begin{alignat*}{3}
    &\lim_{n \to \infty} g_n(x) = \lim_{n \to \infty} \frac{x}{1 + x^n} &&= \begin{cases}
      x & \textrm{if}~x \in [0, 1) \\
      \sfrac{1}{2} & \textrm{if}~x = 1 \\
      0 & \textrm{if}~x > 1 \\
    \end{cases} \\
    \aand& \lim_{n \to \infty} h_n(x) &&= \begin{cases}
      0 & \textrm{if}~x = 0 \\
      1 & \textrm{if}~x > 0
    \end{cases}
  .\tag*{\qedhere}\end{alignat*}
\end{proof}

\begin{proof}[Solution to (ii)]
  It would contract Theorem 6.2.6, since both $g_n$ and $h_n$ are continuous,
  but the limit functions aren't.
\end{proof}

\begin{proof}[Solution to (iii)]
  For $h_n$: Let $\epsilon > 0$. Choose $N > \epsilon$. Then, for all $n \ge N$ on
  the interval $[1, \infty)$, we have
  \[%
    \lvert h_n(x) - h(x) \rvert = \lvert 1 - 1 \rvert = 0 < \epsilon
  .\]%

  For $g_n$: Let $\epsilon > 0$. Choose $N > \log_t(\epsilon)$. Then, for all
  $n \ge N$ on the interval $[0, 1)$, we have
  \[%
    \lvert g_n(x) - g(x) \rvert = \left\lvert \frac{x}{1 + x^n} - x \right\rvert = \left\lvert \frac{x^{n+1}}{1 + x^n} \right\rvert < \left\lvert t^{n+1} \right\rvert < \epsilon
  .\qedhere\]%
\end{proof}

\begin{problem}[7.5.8]
  Let
  \[%
    L(x) = \int_1^x \frac{1}{t} \,\dt
  ,\]%
  where we consider only $x > 0$.

  \begin{enumerate}
    \item What is $L(1)$? Explain why $L$ is differentiable and find $L'(x)$.

    \item Show that $L(xy) = L(x) + L(y)$. (Think of $y$ as a constant and differentiate $g(x) = L(xy)$.)

    \item Show $L(\sfrac{x}{y}) = L(x) - L(y)$.
  \end{enumerate}
\end{problem}

\begin{proof}[Solution to (i)]
  Using the Fundamental Theorem of Calculus, part (i), we have
  \[%
    L(1) = \int_1^1 \frac{1}{t} \,\dt = -\frac{1}{t^2}\bigg|_1^1 = 0
  .\]%
  Since the integrand $\sfrac{1}{t}$ is continuous on $(0, \infty)$, $L$ is differentiable on $(0, \infty)$. By the Fundamental Theorem of Calculus, part (ii), we have
  \[%
    L'(x) = \odv{}{x} \int_1^x \frac{1}{t} \,\dt = \frac{1}{x}
  .\qedhere\]%
\end{proof}

\begin{proof}[Solution to (ii)]
  Let $y$ be a constant. Then, define
  \[%
    g(x) = L(xy) = \int_1^{xy} \frac{1}{t} \,\dt
  .\]%
  Differentiating,
  \[%
    g'(x) = \odv{}{x} \int_1^{xy} \frac{1}{t} \,\dt = \frac{y}{xy} = \frac{1}{x}
  .\]%
  This means $g'(x) = L'(x) \implies g(x) = L(x) + C$. To find $C$, let $x = 1$ and evaluate, giving us
  \[%
    g(1) = L(1) + C \implies L(y) = 0 + C \implies C = L(y)
  .\]%
  Hence, we have
  \[%
    g(x) = L(xy) = L(x) + L(y)
  .\qedhere\]%
\end{proof}

\begin{proof}[Solution to (iii)]
  Let $y$ be a constant. Then, define
  \[%
    g(x) = L\left(\frac{x}{y}\right) = \int_1^{\frac{x}{y}} \frac{1}{t} \,\dt
  .\]%
  Differentiating,
  \[%
    g'(x) = \odv{}{x} \int_1^{\frac{x}{y}} \frac{1}{t} \,\dt = \frac{\sfrac{1}{y}}{\sfrac{x}{y}} = \frac{1}{x}
  .\]%
  This means $g'(x) = L'(x) \implies g(x) = L(x) + C$. To find $C$, let $x = y$ and evaluate, giving us
  \[%
    g(y) = L(1) = L(y) + C \implies 0 = L(y) + C \implies C = -L(y)
  .\]%
  Hence, we have
  \[%
   g(x) = L\left(\frac{x}{y}\right) = L(x) - L(y)
  .\qedhere\]%
\end{proof}

\begin{problem}[S.1]
  Let $g$ be a continuous function and $h$ is a differentiable function. Show
  that the integral below defines a differentiable function and find the
  derivative
  \[%
    \odv{}{x} \int_a^{h(x)} g
  .\]%
\end{problem}

\begin{proof}[Solution]
  Define the function
  \[%
    F(x) = \int_a^{h(x)} g(t) \,\dt
  .\]%
  Since $g$ is continuous and $h$ is differentiable, from the Fundamental
  Theorem of Calculus and the Chain Rule, we have
  \[%
    F'(x) = g(h(x)) \cdot h'(x)
  .\]%
  Hence, $F$ is differentiable, since it's the product of two differentiable
  functions.
\end{proof}

\begin{problem}[S.2]
  Let $g$ be a continuous function on $\R$. Show that each integral below is differentiable and compute the derivative
  \[%
    \textrm{(i)}\quad\odv{}{x} \int_{x-1}^{x+1} g \qquad\qquad\qquad \textrm{(ii)}\quad\odv{}{x} \int_0^x g(t - x) \,\dt
  .\]%
\end{problem}

\begin{proof}[Solution to (i)]
  Define the function
  \[%
    F(x) = \int_{x-1}^{x+1} g(t) \,\dt
  .\]%
  Since $g$ is continuous, from the Fundamental Theorem of Calculus, we have
  \[%
    F'(x) = g(x + 1) \cdot \odv{}{x}(x + 1) - g(x - 1) \cdot \odv{}{x}(x - 1) = g(x + 1) - g(x - 1)
  .\]%
  Again, like the previous problem, $F$ is differentiable, since it's the
  difference of two differentiable composite functions.
\end{proof}

\begin{proof}[Solution to (ii)]
  Define the function
  \[%
    F(x) = \int_0^x g(t - x) \,\dt
  .\]%
  Since $g$ is continuous, from the Fundamental Theorem of Calculus and the
  Chain Rule, we have
  \[%
    F'(x) = g(x - x) \cdot \odv{}{x}(x - x) - g(0 - x) \cdot \odv{}{x} (0 - x) = g(-x)
  .\]%
  Hence, $F$ is differentiable.
\end{proof}
